<!DOCTYPE HTML>

<html>
	<head>
		<title>Blog - How to be a Better Model</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../assets/css/blog.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->

	    <script type="text/x-mathjax-config">
		MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	    </script>
	    <script type="text/x-mathjax-config">
		MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});
	    </script>
	    <script type="text/javascript"
		src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	    </script>
	</head>
	<body id="top">

			<header id="header">
				<div class="inner">
					<a href="../index.html" class="icon fa-long-arrow-left">  back</a>
				</div>
			</header>



		<!-- Main -->
			<div id="main">

					<section id="one">
						<header class="major">
							<h1>How to be a Better Model</h1>
							<h4><i>Joe Marino - November 2016</i></h4>
						</header>
						
						<h3> Preface </h3>

						<p>
						I have decided to take a different direction with this blog post. Rather than delve into the technical details of a particular model or algorithm, I want to briefly discuss some <i>philosophical</i> thoughts I've had since starting graduate school. I think a lot about how to apply insights from what we know about biological intelligence to build machine intelligence. However, the insights often flow equally well in the opposite direction: machine learning often recasts findings from neuroscience in a grounded and principled way. The following is a discussion about what machine learning can teach us about ourselves and how we learn. I hope you find this post thought-provoking, or entertaining at the very least.
						</p>

						<p>
As a student of machine learning and deep learning, I train models for a living. Whether it's fitting a line to a set of points, learning a latent representation, or even classifying images, <b>to perfom any task, you need a model</b>. Machine learning researchers are constantly inventing new models and tweaks to existing models, each promising to solve new tasks, use less data, or be easier to train. It's been thrilling to see the ideas that have come out of this AI spring that we find ourselves in. Yet, even with the multitude of approaches out there, <b>there are some basic, core commonalities to all models</b>. These are principles that apply to the field of machine learning as a whole, and as I'll argue, many of these principles apply to biological learning as well.
						</p>

						<h3> Got data? </h3>

						<p>
						One thing that became apparent to me when I started working in machine learning was the fact that  
						</p>

						<center><h2>a model is only as good as its <u>priors</u> and the <u>data</u> that it's trained on.</h2></center>

						<p>
						Look past the obviousness of this statement for a moment and give it some real thought. Imagine that you've just come up with the most amazing model ever created. You either need 1) a great set of priors on your model and its parameters, in which case you've likely done some form of learning beforehand, or 2) the data required to train the model. Unless you have one (or both) of these, your model is worthless: you won't be able to use it. It'll just sit in its directory on your hard disk, collecting dust. 
						</p>

						<p>
						This general idea, highlighting the importance of data and priors for a well-performing system, also applies to biological learning. We might not look or feel like it, but you and I are both, in some sense, very specialized, complex models of our environments. We're constantly taking in data through our senses, processing and learning from this data, and producing outputs in the form of actions. Each of us also has a set of priors on our nervous systems, 'learned' through the process of natural selection. These are akin to blueprints that specify the overall architecture and functional parts of your nervous system, but typically not the specific way in which things fit together. We are a combination of <em>nature</em>, from our biological priors, and <em>nurture</em>, from the data we encounter.
						</p>


						<center><h2>We are all models of our environments.</h2></center>

						<p>
						So what does this really say about us? It says that who we are as individuals is shaped by our surroundings. Your personality, quality of character, views and opinions, talents and skills and everything you're capable of is a result of the data that you, as well as your ancestors, encountered in the environment. Or conversely, without that data, we wouldn't be us.
						</p>

						<p>
						Now, it's difficult to know what makes for a 'great' human. That's too subjective to even begin to measure. We're no longer judged purely on the basis of our abilities to survive and 

However, I will say this: much of what we admire in other people, such as leadership, intelligence, skill, and perhaps even qualities such as compassion and determination, are learned from data. Improving oneself requires the right data, as well as effort in the form of learning.
						</p>
                        
						<h3> Active Learners </h3>


						<div class="box alt">
							<center>
							<div class="row 50% uniform">
								<div class="6u$"><span class="image fit"><img src="../images/blog_images/blog_VAE/lego_tower.jpg" alt="" /></span></div>
								<p><em>The worldâ€™s tallest lego tower in Milan reaches a height of 35 meters.</em></p>
							</div>
							</center>
						</div>
                        

					<div id="disqus_thread"></div>
					    <script>
						/**
						 * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
						 * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
						 */
					    
					    var disqus_config = function () {
						this.page.url = 'http://joelouismarino.github.io/blog_posts/blog_VAE.html'; // Replace PAGE_URL with your page's canonical URL variable
						this.page.identifier = implementing_backprop; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
					    };
					    
					    (function() { // DON'T EDIT BELOW THIS LINE
					     var d = document, s = d.createElement('script');
					     
					     s.src = '//marinoblog.disqus.com/embed.js';
					     
					     s.setAttribute('data-timestamp', +new Date());
					     (d.head || d.body).appendChild(s);
					     })();
						</script>
					    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
					</section>


					<section id="four">

							<section>
								<p>
								<center>
								&copy; 2016 Joe Marino
								</center>
								</p>
							</section>

					</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
